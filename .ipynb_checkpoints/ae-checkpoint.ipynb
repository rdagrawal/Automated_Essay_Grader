{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re, collections\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data in a pandas dataframe\n",
    "\n",
    "dataframe = pd.read_csv('essays_and_scores.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting relevant columns\n",
    "\n",
    "data = dataframe[['essay_set','essay','domain1_score']].copy()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize a sentence into words\n",
    "\n",
    "def sentence_to_wordlist(raw_sentence):\n",
    "    \n",
    "    clean_sentence = re.sub(\"[^a-zA-Z0-9]\",\" \", raw_sentence)\n",
    "    tokens = nltk.word_tokenize(clean_sentence)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing an essay into a list of word lists\n",
    "\n",
    "def tokenize(essay):\n",
    "    stripped_essay = essay.strip()\n",
    "    \n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(stripped_essay)\n",
    "    \n",
    "    tokenized_sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            tokenized_sentences.append(sentence_to_wordlist(raw_sentence))\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating average word length in an essay\n",
    "\n",
    "def avg_word_len(essay):\n",
    "    \n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    \n",
    "    return sum(len(word) for word in words) / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating number of words in an essay\n",
    "\n",
    "def word_count(essay):\n",
    "    \n",
    "    clean_essay = re.sub(r'\\W', ' ', essay)\n",
    "    words = nltk.word_tokenize(clean_essay)\n",
    "    \n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating number of characters in an essay\n",
    "\n",
    "def char_count(essay):\n",
    "    \n",
    "    clean_essay = re.sub(r'\\s', '', str(essay).lower())\n",
    "    \n",
    "    return len(clean_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating number of sentences in an essay\n",
    "\n",
    "def sent_count(essay):\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(essay)\n",
    "    \n",
    "    return len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating number of lemmas per essay\n",
    "\n",
    "def count_lemmas(essay):\n",
    "    \n",
    "    tokenized_sentences = tokenize(essay)      \n",
    "    \n",
    "    lemmas = []\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for sentence in tokenized_sentences:\n",
    "        tagged_tokens = nltk.pos_tag(sentence) \n",
    "        \n",
    "        for token_tuple in tagged_tokens:\n",
    "        \n",
    "            pos_tag = token_tuple[1]\n",
    "        \n",
    "            if pos_tag.startswith('N'): \n",
    "                pos = wordnet.NOUN\n",
    "                lemmas.append(wordnet_lemmatizer.lemmatize(token_tuple[0], pos))\n",
    "            elif pos_tag.startswith('J'):\n",
    "                pos = wordnet.ADJ\n",
    "                lemmas.append(wordnet_lemmatizer.lemmatize(token_tuple[0], pos))\n",
    "            elif pos_tag.startswith('V'):\n",
    "                pos = wordnet.VERB\n",
    "                lemmas.append(wordnet_lemmatizer.lemmatize(token_tuple[0], pos))\n",
    "            elif pos_tag.startswith('R'):\n",
    "                pos = wordnet.ADV\n",
    "                lemmas.append(wordnet_lemmatizer.lemmatize(token_tuple[0], pos))\n",
    "            else:\n",
    "                pos = wordnet.NOUN\n",
    "                lemmas.append(wordnet_lemmatizer.lemmatize(token_tuple[0], pos))\n",
    "    \n",
    "    lemma_count = len(set(lemmas))\n",
    "    \n",
    "    return lemma_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking number of misspelled words\n",
    "\n",
    "def count_spell_error(essay):\n",
    "    \n",
    "    clean_essay = re.sub(r'\\W', ' ', str(essay).lower())\n",
    "    clean_essay = re.sub(r'[0-9]', '', clean_essay)\n",
    "    \n",
    "    #big.txt: It is a concatenation of public domain book excerpts from Project Gutenberg \n",
    "    #         and lists of most frequent words from Wiktionary and the British National Corpus.\n",
    "    #         It contains about a million words.\n",
    "    data = open('big.txt').read()\n",
    "    \n",
    "    words_ = re.findall('[a-z]+', data.lower())\n",
    "    \n",
    "    word_dict = collections.defaultdict(lambda: 0)\n",
    "                       \n",
    "    for word in words_:\n",
    "        word_dict[word] += 1\n",
    "                       \n",
    "    clean_essay = re.sub(r'\\W', ' ', str(essay).lower())\n",
    "    clean_essay = re.sub(r'[0-9]', '', clean_essay)\n",
    "                        \n",
    "    mispell_count = 0\n",
    "    \n",
    "    words = clean_essay.split()\n",
    "                        \n",
    "    for word in words:\n",
    "        if not word in word_dict:\n",
    "            mispell_count += 1\n",
    "    \n",
    "    return mispell_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating number of nouns, adjectives, verbs and adverbs in an essay\n",
    "\n",
    "def count_pos(essay):\n",
    "    \n",
    "    tokenized_sentences = tokenize(essay)\n",
    "    \n",
    "    noun_count = 0\n",
    "    adj_count = 0\n",
    "    verb_count = 0\n",
    "    adv_count = 0\n",
    "    \n",
    "    for sentence in tokenized_sentences:\n",
    "        tagged_tokens = nltk.pos_tag(sentence)\n",
    "        \n",
    "        for token_tuple in tagged_tokens:\n",
    "            pos_tag = token_tuple[1]\n",
    "        \n",
    "            if pos_tag.startswith('N'): \n",
    "                noun_count += 1\n",
    "            elif pos_tag.startswith('J'):\n",
    "                adj_count += 1\n",
    "            elif pos_tag.startswith('V'):\n",
    "                verb_count += 1\n",
    "            elif pos_tag.startswith('R'):\n",
    "                adv_count += 1\n",
    "            \n",
    "    return noun_count, adj_count, verb_count, adv_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getiing Bag of Words (BOW) counts\n",
    "\n",
    "def get_count_vectors(essays):\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features = 10000, ngram_range=(1, 3), stop_words='english')        #BOW\n",
    "    \n",
    "    count_vectors = vectorizer.fit_transform(essays)             #lear vocunulary dictionary and return document matrix\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names()                    #TFIDF\n",
    "    \n",
    "    return feature_names, count_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train data and test data (70/30)9\n",
    "\n",
    "feature_names_cv, count_vectors = get_count_vectors(data[data['essay_set'] == 1]['essay'])\n",
    "\n",
    "X_cv = count_vectors.toarray()\n",
    "\n",
    "y_cv = data[data['essay_set'] == 1]['domain1_score'].as_matrix()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cv, y_cv, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Linear Regression model using only Bag of Words (BOW)\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linear_regressor.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % linear_regressor.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training a Lasso Regression model (l1 regularization) using only Bag of Words (BOW)\n",
    "\n",
    "alphas = np.array([3, 1, 0.3, 0.1, 0.03, 0.01])\n",
    "\n",
    "lasso_regressor = Lasso()\n",
    "\n",
    "grid = GridSearchCV(estimator = lasso_regressor, param_grid = dict(alpha=alphas))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting essay features\n",
    "\n",
    "def extract_features(data):\n",
    "    \n",
    "    features = data.copy()\n",
    "    \n",
    "    features['char_count'] = features['essay'].apply(char_count)\n",
    "    \n",
    "    features['word_count'] = features['essay'].apply(word_count)\n",
    "    \n",
    "    features['sent_count'] = features['essay'].apply(sent_count)\n",
    "    \n",
    "    features['avg_word_len'] = features['essay'].apply(avg_word_len)\n",
    "    \n",
    "    features['lemma_count'] = features['essay'].apply(count_lemmas)\n",
    "    \n",
    "    features['spell_err_count'] = features['essay'].apply(count_spell_error)\n",
    "    \n",
    "    features['noun_count'], features['adj_count'], features['verb_count'], features['adv_count'] = zip(*features['essay'].map(count_pos))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features from essay set 1\n",
    "\n",
    "features_set1 = extract_features(data[data['essay_set'] == 1])\n",
    "\n",
    "print(features_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA) on the data\n",
    "\n",
    "%matplotlib inline\n",
    "features_set1.plot.scatter(x = 'char_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'word_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'sent_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'avg_word_len', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'lemma_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'spell_err_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'noun_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'adj_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'verb_count', y = 'domain1_score', s=10)\n",
    "features_set1.plot.scatter(x = 'adv_count', y = 'domain1_score', s=10)\n",
    "\n",
    "# Essay Set 1 Trends:\n",
    "\n",
    "# By plotting the below scatter plots, we can examine how different features above affect the grade the student receives.\n",
    "\n",
    "# 1. I observed that there is a strong correlation between character count of an essay and the final essay score. \n",
    "#    I observed similar correlations for word count, sentence count and lemma count of an essay.\n",
    "#    These features indicate language fluency and dexterity.\n",
    "# 2. Various parts-of-speech such as nouns, adjectives adverbs and verbs are good proxies to test vocabulary. \n",
    "#    This feature can also be taken as a rudimentary proxy for diction.\n",
    "#    I observed a strong correlation between noun_count and the final essay score. Sililar trends were observed for verb count,\n",
    "#    adjective count and adverb count of an essay.\n",
    "# 3. I did not observe any significant correlation between average word length of an essay and its score.\n",
    "# 4. There is a weaker correlation between the number of spelling errors and the final score of an essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data (BOW + other features) into train data and test data (70/30)\n",
    "    \n",
    "X = np.concatenate((features_set1.iloc[:, 3:].as_matrix(), X_cv), axis = 1)\n",
    "\n",
    "y = features_set1['domain1_score'].as_matrix()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Linear Regression model using all the features (BOW + other features)\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linear_regressor.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % linear_regressor.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Ridge Regression model (l2 regularization) using all the features (BOW + other features)\n",
    "\n",
    "alphas = np.array([3, 1, 0.3, 0.1])\n",
    "\n",
    "ridge_regressor = Ridge()\n",
    "\n",
    "grid = GridSearchCV(estimator = ridge_regressor, param_grid = dict(alpha=alphas))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Lasso Regression model (l1 regularization) using all the features (BOW + other features)\n",
    "\n",
    "alphas = np.array([3, 1, 0.3, 0.1])\n",
    "\n",
    "lasso_regressor = Lasso()\n",
    "\n",
    "grid = GridSearchCV(estimator = lasso_regressor, param_grid = dict(alpha=alphas))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Gradient Boosting Regression model using all the features (BOW + other features)\n",
    "\n",
    "params = {'n_estimators':[100, 1000], 'max_depth':[2], 'min_samples_split': [2],\n",
    "          'learning_rate':[3, 1, 0.1, 0.3], 'loss': ['ls']}\n",
    "\n",
    "gbr = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "grid = GridSearchCV(gbr, params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))\n",
    "\n",
    "# Plot feature importance - to find the main factors affecting the final grade\n",
    "feature_importance = grid.best_estimator_.feature_importances_\n",
    "\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "feature_names = list(features_set1.iloc[:, 3:].columns.values)\n",
    "feature_names = np.asarray(feature_names + feature_names_cv)\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "# get top 100\n",
    "sorted_idx = sorted_idx[9910:]\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, feature_names[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data (only 10 numerical/POS/orthographic features) into train data and test data (70/30)\n",
    "    \n",
    "X = features_set1.iloc[:, 3:].as_matrix()\n",
    "\n",
    "y = features_set1['domain1_score'].as_matrix()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Linear Regression model using only 10 numerical/POS/orthographic features\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linear_regressor.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % linear_regressor.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Ridge Regression model (l2 regularization) using only 10 numerical/POS/orthographic features\n",
    "\n",
    "alphas = np.array([3, 1, 0, 0.3, 0.1, 0.03, 0.01, 0.003, 0.001])\n",
    "\n",
    "ridge_regressor = Ridge()\n",
    "\n",
    "grid = GridSearchCV(estimator = ridge_regressor, param_grid = dict(alpha=alphas))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Lasso Regression model (l1 regularization) using only 10 numerical/POS/orthographic features\n",
    "\n",
    "alphas = np.array([3, 1, 0.3, 0.1, 0.3])\n",
    "\n",
    "lasso_regressor = Lasso()\n",
    "\n",
    "grid = GridSearchCV(estimator = lasso_regressor, param_grid = dict(alpha=alphas))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Gradient Boosting Regression model using only 10 numerical/POS/orthographic features\n",
    "\n",
    "params = {'n_estimators':[50, 100, 500, 1000], 'max_depth':[2], 'min_samples_split': [2],\n",
    "          'learning_rate':[1, 0.1, 0.3, 0.01], 'loss': ['ls']}\n",
    "\n",
    "gbr = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "grid = GridSearchCV(gbr, params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))\n",
    "\n",
    "# Plot feature importance - to find the main factors affecting the final grade\n",
    "feature_importance = grid.best_estimator_.feature_importances_\n",
    "\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "feature_names = list(features_set1.iloc[:, 3:].columns.values)\n",
    "feature_names = np.asarray(feature_names)\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, feature_names[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Support Vector Regression model using only 10 numerical/POS/orthographic features\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "parameters = {'kernel':['linear', 'rbf'], 'C':[1, 100], 'gamma':[0.1, 0.001]}\n",
    "\n",
    "grid = GridSearchCV(svr, parameters)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % grid.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
